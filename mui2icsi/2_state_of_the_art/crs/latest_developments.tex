The methodologies for building \acp{crs} have evolved significantly, moving from modular, pipeline-based systems to more integrated, end-to-end frameworks powered by modern \acp{llm}.

\paragraph{Preference Elicitation Strategies}
The core task of any \ac{crs} is to understand user preferences through conversation. Early research focused on several notable strategies for this \textbf{preference elicitation} process \cite[Section 3]{CHAPTER:RS-HANDBOOK-NLP}:
\begin{compactitem}[\textbullet]
    \item \textbf{Critiquing:} In this paradigm, the system presents a set of recommendations, and the user refines them by providing natural language critiques or constraints (e.g., ``show me something cheaper''). This allows for an iterative narrowing of the search space based on direct feedback \cite[Section 3.2]{CHAPTER:RS-HANDBOOK-NLP}.
    \item \textbf{Facets-Based Elicitation:} Here, the system identifies primary item attributes, or \textit{facets} (e.g., genre, brand, color), and asks targeted questions about them to build a structured representation of the user's needs \cite[Section 3.3]{CHAPTER:RS-HANDBOOK-NLP}.
    \item \textbf{Question-Driven Approaches:} More advanced systems strategically decide which questions to ask to maximize information gain. The \textbf{System Ask, User Respond (SAUR)} model is a well-known formalization of this, where the system learns a policy for asking clarification questions to efficiently guide the conversation toward a successful recommendation \cite[Section 3.4.1]{CHAPTER:RS-HANDBOOK-NLP}.
\end{compactitem}

\paragraph{Towards LLM-Native Architectures}
A significant recent trend is the move away from complex, multi-component architectures towards unified frameworks that formulate the entire \ac{crs} task as a language problem. While older toolkits like \texttt{CRSLab} \cite{CRSLAB} treated recommendation, dialogue, and policy as separate, interconnected modules, modern approaches leverage a single, powerful \ac{llm} to handle multiple functions simultaneously \cite[Section 2.2]{SURVEY-HOLISTIC-RECSYS}. Frameworks like \texttt{RecInDial} \cite{RECINDIAL} demonstrate this by using a pre-trained language model to unify the understanding of conversational context and the generation of both dialogue responses and item recommendations, removing the semantic gap that often exists between separate modules.

\paragraph{Reinforcement Learning for Dialogue Policy Optimization}
To optimize the multi-turn conversational strategy, Reinforcement Learning (RL) has emerged as a state-of-the-art approach \cite{SOTA-DIALOGUE-RL}. In this paradigm, the \ac{crs} is framed as an agent that learns an optimal \textit{dialogue policy} through trial and error. At each turn of the conversation, the agent must decide on an action (e.g., ask about an attribute, recommend an item) to maximize a cumulative long-term reward, which is typically a function of user satisfaction and conversation efficiency. This allows the system to learn sophisticated strategies that balance exploration (gathering more information about user preferences) and exploitation (making recommendations based on current knowledge) \cite{SOTA-CR}.

\paragraph{Holistic vs. Simulated Systems}
A critical distinction in modern \ac{crs} research is the nature of the data used for training and evaluation. Early work relied on \textit{simulated} user interactions, which, while useful for optimizing algorithms, fails to capture the complexity and unpredictability of real human conversation. In response, the field is increasingly moving towards building and evaluating \textbf{holistic} \acp{crs} \cite{SURVEY-HOLISTIC-RECSYS}. A holistic system is one that is trained and evaluated end-to-end on datasets of real human-to-system conversations. This shift requires more comprehensive evaluation, assessing not only recommendation accuracy but also the linguistic quality and coherence of the dialogue itself.