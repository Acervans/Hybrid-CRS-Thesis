As \aclp{rs} become more powerful and integrated into daily decision-making, the need for transparency and accountability has grown from a desirable feature to an important requirement. \acl{xai} is the field dedicated to addressing this need, aiming to make the decisions of \ac{ai} systems understandable to humans. In the context of \acp{rs}, explanations can significantly improve user satisfaction, enhance trust, increase the persuasiveness of recommendations, and provide a level of transparency that helps users make more effective decisions \cite{SOTA-RECSYS-EXPLAIN}.

This need is amplified in \aclp{crs}. An explanation is not merely a static justification appended to a recommendation; it is an active component of the dialogue, acting as a way of gathering more accurate user feedback. By presenting the reasons for a recommendation (e.g., ``I'm suggesting this movie because it shares an actor you like''), the system invites the user to agree or disagree with those specific reasons, enabling a collaborative refinement of both the recommendations and the system's understanding of the user's preferences. This section establishes a formal taxonomy for classifying \ac{xai} methods, surveys the most popular explanation generation techniques, and concludes by discussing the complex challenge of evaluating explanation quality.
