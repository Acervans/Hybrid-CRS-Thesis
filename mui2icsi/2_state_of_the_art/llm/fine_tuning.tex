Fine-tuning is the process of further training a pre-trained \ac{llm} on a smaller, domain-specific dataset. The goal is to adapt the model's behavior, style, or knowledge to a specific task. This stands in contrast to in-context learning, which is facilitated by \ac{rag} and does not update the model's weights. While full fine-tuning can be computationally expensive, more efficient methods like Low-Rank Adaptation (LoRA) have been developed to reduce the resource requirements \cite{LORA}. For this project, a \ac{rag}-based approach was chosen over fine-tuning, motivated by the fact that \ac{rag} is often more effective and manageable for incorporating new or rapidly changing factual knowledge (such as an item catalog) and avoids the high computational cost and potential for ``catastrophic forgetting'' that can occur during fine-tuning.