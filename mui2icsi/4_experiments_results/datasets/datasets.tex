To evaluate the implemented system, two publicly available datasets from different domains were selected. These datasets were chosen to test the platform's data processing pipeline and to provide a basis for the user-centric evaluation of the conversational agents. The first is the \texttt{MovieLens-100k} dataset, a standard benchmark in \aclp{rs} research. The second is a larger-scale dataset of user preferences for anime. The key statistics for both are summarized in Table~\ref{TAB:DATASET_STATS}.

\begin{table}[Datasets Statistics]{TAB:DATASET_STATS}{Key statistics of the datasets used in the experiments.}
    \begin{tabular}{l r r}
        \hline
        \textbf{Statistic} & \textbf{MovieLens-100k} & \textbf{Anime} \\
        \hline
        Domain & Movies & Anime \\
        \# Users & 943 & 73,515 \\
        \# Items & 1,682 & 12,294 \\
        \# Interactions & 100,000 & 7,813,737 \\
        Data Sparsity & 93.7\% & 99.1\% \\
        \hline
    \end{tabular}
\end{table}