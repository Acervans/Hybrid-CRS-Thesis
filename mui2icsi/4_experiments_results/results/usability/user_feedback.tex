In addition to the positive feedback, the usability study yielded several points of constructive feedback and valuable suggestions for improvement. A recurring theme was that in initial conversational turns (the cold-start phase), the recommendations could sometimes be generic and focused on popular items. Users also noted that the agent's ability to interpret context was limited when prompts included specific attributes not present in the item dataset.

Based on this feedback, several areas for future enhancement were identified:
\begin{compactitem}[\textbullet]
    \item \textbf{Improved Context Awareness:} Enhancing the \ac{llm}'s ability to handle queries that fall outside the dataset's explicit schema.
    \item \textbf{Recommendation Transparency:} Adding labels or tags to recommendations to clarify their origin (e.g., \acl{cf} vs. Content-based).
    \item \textbf{Better Feedback Interface:} Modifying the rating interface for unseen items, for instance, by first asking for confirmation of viewership before presenting a rating slider.
    \item \textbf{User Onboarding:} Implementing a brief tutorial or context-sensitive tooltips to guide new users through more complex features like the agent creation process.
\end{compactitem}

\newpage