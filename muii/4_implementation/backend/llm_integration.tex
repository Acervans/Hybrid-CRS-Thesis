The conversational capabilities of the platform are powered by the integration with open-source \acp{llm} served via Ollama. The core of this integration is the \texttt{HybridCRSWorkflow} class, which is built using the LlamaIndex framework \cite{LLAMAINDEX}. This class defines a stateful, event-driven workflow for managing a conversation between a user and a recommender agent.

At a high level, the workflow is responsible for maintaining the conversational context, parsing user inputs, and coordinating the use of tools---specifically, the recommender functions. When a recommendation is required, the workflow triggers a function call to the appropriate method in the recommendation module. The results are then fed back into the \ac{llm} to be synthesized into a natural language response, which is streamed back to the user. This high-level oversight abstracts the complexity of the \ac{llm} interaction. The specific design of the conversational flow, prompt engineering, and user-preference elicitation strategies are research topics explored in greater detail in the complementary thesis \cite{MUI2ICSI-THESIS}.